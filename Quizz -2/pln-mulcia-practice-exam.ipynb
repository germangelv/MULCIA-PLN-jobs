{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "924d7296",
   "metadata": {},
   "source": [
    "## Apartado 1\n",
    "Se debe implementar un sistema que permita recibir una expresión como entrada (será una expresión\n",
    "formada solo por minúsculas y sin los signos de puntuación mencionados (los seis signos con los que\n",
    "vamos a trabajar en este ejercicio y que serán siempre, el punto, la coma, los dos puntos, el punto y\n",
    "coma, el signo de cierre de interrogación y de exclamación: `.,;:?!`), y la salida será la misma\n",
    "expresión pero con los cambios correspondientes a la introducción de mayúsculas y signos de\n",
    "puntuación indicados.\n",
    "A un nivel alto de especificación podremos considerar que este método tiene esta signatura:\n",
    "`string addPunctuationBasic(string)`\n",
    "\n",
    "Es decir recibirá como entrada un string y devolverá como salida un string.\n",
    "Como primera versión de esta función addPunctuationBasic se implementará un modelo que\n",
    "simplemente cambia la primera letra por mayúscula y añade al final del string de entrada un punto.\n",
    "Por ejemplo, al ejecutar\n",
    "\n",
    "`addPunctuationBasic(“it can be a very complicated thing the ocean”)`\n",
    "se obtendrá\n",
    "\n",
    ">It can be a very complicated thing the ocean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07821f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "EnvironmentLocationNotFound: Not a conda environment: /home/germanlorenz/proyectos/MULCIA-PLN-jobs/Quizz -2/{sys.prefix}\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!conda install --yes --prefix {sys.prefix} numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "438e31ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos corpus de test\n",
    "with open('PunctuationTask.test.en') as f:\n",
    "    PunctuationTaskTestEn = f.readlines()\n",
    "# Cargamos corpus de check\n",
    "with open('PunctuationTask.check.en') as f:\n",
    "    PunctuationTaskCheckEn = f.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da216c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it can be a very complicated thing the ocean \n",
      "\n",
      "It can be a very complicated thing, the ocean. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificamos\n",
    "print(PunctuationTaskTestEn[0])\n",
    "print(PunctuationTaskCheckEn[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4671b404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addPunctuationBasic(line):\n",
    "    # Convertimos el primer caracter de la oración a mayuscula\n",
    "    first_letter = line[0].upper()\n",
    "    # Concatenamos el caracter convertido con la oración comenzando desde el segundo caracter a n \n",
    "    # caracteR\n",
    "    formatted_line = first_letter + line[1:]\n",
    "    band = True\n",
    "    # Tratameinto de puntuacion final operando con posibles espacios a eliminar y el retorno de carro\n",
    "    if formatted_line[-1] == '\\n':\n",
    "        formatted_line = formatted_line[:-1]\n",
    "        while band == True:\n",
    "            band = False\n",
    "            if formatted_line[-1] == ' ':\n",
    "                formatted_line = formatted_line[:-1]\n",
    "                band = True\n",
    "            else:\n",
    "                band = False\n",
    "    formatted_line = formatted_line + '.'\n",
    "    return formatted_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc3f7d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vamos a probar la puntuación básica.\n",
      "We made the ocean unhappy we made people very unhappy and we made them unhealthy.\n"
     ]
    }
   ],
   "source": [
    "# Probamos con un ejemplo y con el corpus de test\n",
    "frase = 'vamos a probar la puntuación básica'\n",
    "print(addPunctuationBasic(frase))\n",
    "print(addPunctuationBasic(PunctuationTaskTestEn[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33872e54",
   "metadata": {},
   "source": [
    "## Apartado 2\n",
    "Implementar la función verifyPunctuation con la siguiente signatura\n",
    "`[(pos,err)] verifyPunctuation(string check, string test)`\n",
    "\n",
    "Para realizar esta operación se llevará a cabo una tokenización de ambos strings. En este caso se\n",
    "considerarán tokens todas las secuencias de letras, números y cualquier otro signo que no sea uno de\n",
    "los seis indicados como signos de puntuación en este ejercicio (`.,;:?!`)\n",
    "Es decir, esta función devolverá una lista de pares, donde cada par contendrá la posición (indicada\n",
    "como índice en el string check) y el tipo de error. Los errores posibles son:\n",
    "* ‘I’ → Insertion\n",
    "* ‘D’ → Deletion\n",
    "* ‘S’ → Substitution\n",
    "\n",
    "Por ejemplo, consideremos que el string de referencia correcto (check) es\n",
    "“Hello. What’s your name?”\n",
    "La tokenización generará los siguientes 6 tokens de referencia\n",
    "* Token 0: Hello\n",
    "* Token 1: .\n",
    "* Token 2: What’s\n",
    "* Token 3: your\n",
    "* Token 4: name\n",
    "* Token 5: ?\n",
    "\n",
    "Consideremos que nuestro algoritmo de puntuación (un caso hipotético para analizar el algoritmo de\n",
    "verificación) genera la siguiente salida\n",
    ">“Hello what’s your, name?”\n",
    "\n",
    "Es decir los tokens generados en este caso son:\n",
    "* Token 0: Hello\n",
    "* Token 1: what’s\n",
    "* Token 2: your\n",
    "* Token 3: ,\n",
    "* Token 4: name\n",
    "* Token 5: ?\n",
    "\n",
    "Debemos devolver la lista de cambios necesarios para convertir la cadena de tokens generados\n",
    "(hipótesis) en la cadena de tokens correctos. Para ello, podemos inspirarnos en el algoritmo de la\n",
    "distancia de Levenshtein. Es importante tener en cuenta que dadas dos cadenas A y B:\n",
    "> Dist(A,B) == Dist(B,A)\n",
    "\n",
    "Por lo que podemos abordar el problema tanto desde el punto de los cambios que hay que hacer para\n",
    "llegar desde la hipótesis hasta el modelo correcto, o bien desde el modelo correco (referencia o check\n",
    "en la terminología de este ejercicio) hasta la hipótesis generada por nuestro algoritmo de puntuación.\n",
    "Podemos ver que respecto a nuestro string de referencia (check), el string de test ha ignorado (podemos\n",
    "decir que borrado respecto al de referencia un ., por tanto tendríamos el error\n",
    ">(‘D’,1)\n",
    "\n",
    "En segundo lugar, el token 2 del string de referencia (check) se ha quedado mal en el string de test ya\n",
    "que en lugar de “What’s” aparece “what’s”. Se trata por tanto de un error de substitución de una palabra\n",
    "por otra (en este caso por un error de introducción de mayúsculas):\n",
    ">(‘S’,2)\n",
    "\n",
    "Y en tercer lugar, entre los tokens ‘your’ y ‘name’ del string correcto (check) se ha introducido un\n",
    "nuevo token en el string de test, una coma en concreto, por tanto hay un error que calificaríamos como\n",
    ">(‘I’,4)\n",
    "\n",
    "Como se puede observar, todos los errores se posicionan (usan los índices) respecto al string correcto\n",
    "de referencia (check).\n",
    "Así pues el resultado de\n",
    "\n",
    "`verifyPunctuation(“Hello. What’s your name?”,`\n",
    "`“Hello what’s your, name?”)`\n",
    "\n",
    "sería\n",
    "\n",
    "> [ (‘D’,1), (‘S’,2), (‘I’, 4) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71127441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para tokenizar\n",
    "def tokenizador(texto, tokens):\n",
    "    \n",
    "    # Verificacion strings con datos\n",
    "    if len(texto) == 0: return 0\n",
    "    texto_tokenizado = []\n",
    "    \n",
    "    # Generacion de tokens\n",
    "    start = 0\n",
    "    for i in range(len(texto)):\n",
    "        # Espacios\n",
    "        if texto[i] == ' ':\n",
    "            texto_tokenizado.append(texto[start:i])\n",
    "            start=i+1  \n",
    "        # Analisis de prueba con tokens\n",
    "        for j in range (len(tokens)):\n",
    "            # tokens\n",
    "            if texto[i] == tokens[j]:\n",
    "                texto_tokenizado.append(texto[start:i])\n",
    "                start=i\n",
    "    return texto_tokenizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "015d7972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference explanation https://python-course.eu/applications-python/levenshtein-distance.php\n",
    "def iterative_levenshtein(s, t):\n",
    "    \"\"\" \n",
    "        iterative_levenshtein(s, t) -> ldist\n",
    "        ldist is the Levenshtein distance between the strings \n",
    "        s and t.\n",
    "        For all i and j, dist[i,j] will contain the Levenshtein \n",
    "        distance between the first i characters of s and the \n",
    "        first j characters of t\n",
    "    \"\"\"\n",
    "\n",
    "    rows = len(s)+1\n",
    "    cols = len(t)+1\n",
    "    dist = [[0 for x in range(cols)] for x in range(rows)]\n",
    "\n",
    "    # source prefixes can be transformed into empty strings \n",
    "    # by deletions:\n",
    "    for i in range(1, rows):\n",
    "        dist[i][0] = i\n",
    "\n",
    "    # target prefixes can be created from an empty source string\n",
    "    # by inserting the characters\n",
    "    for i in range(1, cols):\n",
    "        dist[0][i] = i\n",
    "        \n",
    "    for col in range(1, cols):\n",
    "        for row in range(1, rows):\n",
    "            if s[row-1] == t[col-1]:\n",
    "                cost = 0\n",
    "            else:\n",
    "                cost = 1\n",
    "            dist[row][col] = min(dist[row-1][col] + 1,      # deletion\n",
    "                                 dist[row][col-1] + 1,      # insertion\n",
    "                                 dist[row-1][col-1] + cost) # substitution\n",
    "\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5a345d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-lectura de matriz pra detectar camino optimo\n",
    "def minimal_operations(matriz_levenshtein, check_len, test_len):\n",
    "  \n",
    "    # Generando informe\n",
    "    col = test_len\n",
    "    row = check_len\n",
    "    problemas = []\n",
    "    while col > 1:\n",
    "        while row > 1:\n",
    "            # print(\"col: \"+str(col)+\" fil: \"+str(row)+\" max fil col : \"+str(check_len)+\" \"+str(test_len))\n",
    "            # print(\"D: \"+str(matriz_levenshtein[row-1][col])+\" I: \"+str(matriz_levenshtein[row][col-1])\n",
    "            #       +\" S: \"+str(matriz_levenshtein[row-1][col-1]))\n",
    "            \n",
    "            \n",
    "            minimo = min(matriz_levenshtein[row-1][col],    # deletion\n",
    "                         matriz_levenshtein[row][col-1],   # insertion\n",
    "                         matriz_levenshtein[row-1][col-1]) # substitution\n",
    "            # Diagonalizo\n",
    "            \n",
    "            if matriz_levenshtein[row-1][col-1] == minimo:\n",
    "                if matriz_levenshtein[row-1][col-1] == matriz_levenshtein[row][col] - 1:\n",
    "                    # Substitution\n",
    "                    problemas.append(\"S,\"+str(row))\n",
    "                col = col - 1\n",
    "                row = row - 1\n",
    "            elif matriz_levenshtein[row-1][col] == minimo:\n",
    "                # Deletion\n",
    "                problemas.append(\"D,\"+str(row))\n",
    "                row = row - 1\n",
    "            else:\n",
    "                # Insertion\n",
    "                problemas.append(\"I,\"+str(row))\n",
    "                col = col - 1\n",
    "\n",
    "    return np.flip(problemas)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "159784eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifyPunctuation(check, test, tokenizar=True, extended_report=False):\n",
    "    # Analizamos distancias según casos posibles combinando situaciones\n",
    "    # Agregue reporte para poder visualizar la matriz en las pruebas\n",
    "    # Agregue tokenizador para simplificar el procesamiento ya que el enunciado no es claro\n",
    "    \n",
    "    # Tokens reservados\n",
    "    reserve_tokens = ['.',',',';',':','?','!']\n",
    "\n",
    "    if tokenizar:\n",
    "        # Tokenizamos input\n",
    "        data_check = tokenizador(check, reserve_tokens)\n",
    "        data_test = tokenizador(test, reserve_tokens)\n",
    "    else:\n",
    "        data_check = check\n",
    "        data_test = test\n",
    "\n",
    "    matriz_levenshtein = iterative_levenshtein(data_check, data_test)\n",
    "\n",
    "    # Generar reporte\n",
    "    if extended_report:\n",
    "        # Impresion de verificacion, opcional\n",
    "        print('DATOS CORRECTOS')\n",
    "        print(data_check)\n",
    "        print('DATOS A SER PROBADOS')\n",
    "        print(data_test)\n",
    "        \n",
    "        # Impresion Matriz Levenshtein opcional\n",
    "        rows = len(data_check)+1\n",
    "        for r in range(rows):\n",
    "            print(matriz_levenshtein[r])\n",
    "            \n",
    "    # Exportar camino\n",
    "    return minimal_operations(matriz_levenshtein, len(data_check), len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee148b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATOS CORRECTOS\n",
      "Hello. What’s your name?\n",
      "DATOS A SER PROBADOS\n",
      "Hello what’s your, name?\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "[1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
      "[2, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
      "[3, 2, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
      "[4, 3, 2, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "[5, 4, 3, 2, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[6, 5, 4, 3, 2, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[7, 6, 5, 4, 3, 2, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "[8, 7, 6, 5, 4, 3, 2, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "[9, 8, 7, 6, 5, 4, 3, 3, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "[10, 9, 8, 7, 6, 5, 4, 4, 3, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "[11, 10, 9, 8, 7, 6, 5, 5, 4, 3, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "[12, 11, 10, 9, 8, 7, 6, 6, 5, 4, 3, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "[13, 12, 11, 10, 9, 8, 7, 7, 6, 5, 4, 3, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "[14, 13, 12, 11, 10, 9, 8, 8, 7, 6, 5, 4, 3, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "[15, 14, 13, 12, 11, 10, 9, 9, 8, 7, 6, 5, 4, 3, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "[16, 15, 14, 13, 12, 11, 10, 10, 9, 8, 7, 6, 5, 4, 3, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "[17, 16, 15, 14, 13, 12, 11, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[18, 17, 16, 15, 14, 13, 12, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[19, 18, 17, 16, 15, 14, 13, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 3, 3, 4, 5, 6, 7, 8]\n",
      "[20, 19, 18, 17, 16, 15, 14, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 4, 4, 3, 4, 5, 6, 7]\n",
      "[21, 20, 19, 18, 17, 16, 15, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 5, 5, 4, 3, 4, 5, 6]\n",
      "[22, 21, 20, 19, 18, 17, 16, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 6, 6, 5, 4, 3, 4, 5]\n",
      "[23, 22, 21, 20, 19, 18, 17, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 7, 7, 6, 5, 4, 3, 4]\n",
      "[24, 23, 22, 21, 20, 19, 18, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 8, 8, 7, 6, 5, 4, 3]\n",
      "['D,6' 'S,8' 'I,18']\n",
      "DATOS CORRECTOS\n",
      "['Hello', '.', 'What’s', 'your', 'name']\n",
      "DATOS A SER PROBADOS\n",
      "['Hello', 'what’s', 'your', ',', 'name']\n",
      "[0, 1, 2, 3, 4, 5]\n",
      "[1, 0, 1, 2, 3, 4]\n",
      "[2, 1, 1, 2, 3, 4]\n",
      "[3, 2, 2, 2, 3, 4]\n",
      "[4, 3, 3, 2, 3, 4]\n",
      "[5, 4, 4, 3, 3, 3]\n",
      "['S,2' 'S,3' 'S,4']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Prueba de Apartado 2 tokenizada y sin tokenizar\n",
    "str1 = 'Hello. What’s your name?'\n",
    "str2 = 'Hello what’s your, name?'\n",
    "\n",
    "print(verifyPunctuation(str1,str2, tokenizar = False, extended_report = True ))\n",
    "print(verifyPunctuation(str1,str2, tokenizar = True, extended_report = True))\n",
    "print(verifyPunctuation(\"Manhattan\",\"Manahaton\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a09123a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D,6' 'D,12' 'D,18']\n"
     ]
    }
   ],
   "source": [
    "# Prueba de corpus tokenizado y sin tokenizar\n",
    "print(verifyPunctuation(PunctuationTaskCheckEn[3],PunctuationTaskTestEn[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3cf9a5",
   "metadata": {},
   "source": [
    "## Apartado 3\n",
    "\n",
    "Implementar una herramienta que permita recorrer todo el corpus de test y verificación. Es decir, iría\n",
    "recorriendo una a una las líneas de cada fichero (que están alineadas), aplicaría sobre la frase de test el\n",
    "algoritmo básico de puntuación (apartado 1: `addPunctuationBasic()` ) y a continuación\n",
    "comprobaría si el resultado es o no correcto usando la función `verifyPunctuation()` del\n",
    "apartado 2.\n",
    "\n",
    "Obtener a continuación los valores relativos a `precisión`, exhaustividad (`recall`) y `F1` para el algoritmo\n",
    "`addPunctuationBasic()` implementado en el apartado 1.\n",
    "\n",
    "Consideraremos estos valores como el baseline, el modelo más básico de puntuación que podemos\n",
    "realizar para estudiar posibles mejoras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3ecd97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: parse error near `-m'\r\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install tqdm\n",
    "# Progreso\n",
    "from tqdm import tqdm\n",
    "\n",
    "def analysis(check, test, precisión, recall, F1):\n",
    "    \n",
    "    testProceced = []\n",
    "    # Obtengo frases de test procesadas con su puntuacion\n",
    "    for i in tqdm(range(len(test)),ncols = 100, desc=\"Agrego puntuacion ...  \"):\n",
    "        testProceced.append(addPunctuationBasic(test[i]))\n",
    "    \n",
    "    test_analysis = []\n",
    "    # Obtengo fidelidad del corpus de test\n",
    "    for i in tqdm(range(len(test)),ncols = 100 , desc =\"Verifico puntuacion ...\", disable = False):\n",
    "        test_analysis.append(verifyPunctuation(check[i], testProceced[i]))\n",
    "        \n",
    "        \n",
    "    print(len(test_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5373d69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Agrego puntuacion ...  : 100%|████████████████████████████| 14382/14382 [00:00<00:00, 998848.86it/s]\n",
      "Verifico puntuacion ...:  38%|███████████▉                   | 5516/14382 [00:02<00:03, 2887.76it/s]"
     ]
    }
   ],
   "source": [
    "analysis(PunctuationTaskCheckEn, PunctuationTaskTestEn, precisión=True, recall=True, F1=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26dc1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0cef4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iacd",
   "language": "python",
   "name": "iacd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
