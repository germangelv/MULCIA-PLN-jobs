{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "924d7296",
      "metadata": {
        "id": "924d7296"
      },
      "source": [
        "## Apartado 1\n",
        "Se debe implementar un sistema que permita recibir una expresión como entrada (será una expresión\n",
        "formada solo por minúsculas y sin los signos de puntuación mencionados (los seis signos con los que\n",
        "vamos a trabajar en este ejercicio y que serán siempre, el punto, la coma, los dos puntos, el punto y\n",
        "coma, el signo de cierre de interrogación y de exclamación: `.,;:?!`), y la salida será la misma\n",
        "expresión pero con los cambios correspondientes a la introducción de mayúsculas y signos de\n",
        "puntuación indicados.\n",
        "A un nivel alto de especificación podremos considerar que este método tiene esta signatura:\n",
        "`string addPunctuationBasic(string)`\n",
        "\n",
        "Es decir recibirá como entrada un string y devolverá como salida un string.\n",
        "Como primera versión de esta función addPunctuationBasic se implementará un modelo que\n",
        "simplemente cambia la primera letra por mayúscula y añade al final del string de entrada un punto.\n",
        "Por ejemplo, al ejecutar\n",
        "\n",
        "`addPunctuationBasic(“it can be a very complicated thing the ocean”)`\n",
        "se obtendrá\n",
        "\n",
        ">It can be a very complicated thing the ocean."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2f6eca1",
      "metadata": {
        "id": "f2f6eca1"
      },
      "source": [
        "Agregó script para instalar las librerías requeridas por el proyecto. Dejo la opción de conda o directamente entorno python local.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07821f0f",
      "metadata": {
        "id": "07821f0f",
        "outputId": "6b9f7c5d-ebd1-4687-c5c4-11a1dfb99793"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sklearn\n",
            "  Using cached sklearn-0.0.tar.gz (1.1 kB)\n",
            "Requirement already satisfied: scikit-learn in /home/germanlorenz/anaconda3/lib/python3.9/site-packages (from sklearn) (0.24.2)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /home/germanlorenz/anaconda3/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.7.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /home/germanlorenz/anaconda3/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.20.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /home/germanlorenz/anaconda3/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/germanlorenz/anaconda3/lib/python3.9/site-packages (from scikit-learn->sklearn) (2.2.0)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1303 sha256=68bef46aab5ee27e3124ffe112dbfa28312ebb8ec5b339c20af7d4dda53da4d2\n",
            "  Stored in directory: /home/germanlorenz/.cache/pip/wheels/e4/7b/98/b6466d71b8d738a0c547008b9eb39bf8676d1ff6ca4b22af1c\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "# Instalaciones directas en contexto conda\n",
        "# !conda install --yes --prefix {sys.prefix} numpy\n",
        "# !conda install --yes --prefix {sys.prefix} tqdm\n",
        "# !conda install --yes --prefix {sys.prefix} sklearn\n",
        "\n",
        "# Verificaciones para python\n",
        "libraryList = !{sys.executable} -m pip list\n",
        "if len(list(filter(lambda x: 'numpy ' in x, libraryList))) == 0:\n",
        "    !{sys.executable} -m pip install numpy\n",
        "if len(list(filter(lambda x: 'tqdm ' in x, libraryList))) == 0:\n",
        "    !{sys.executable} -m pip install tqdm\n",
        "if len(list(filter(lambda x: 'sklearn ' in x, libraryList))) == 0:\n",
        "    !{sys.executable} -m pip install sklearn\n",
        "    \n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6c5212d",
      "metadata": {
        "id": "e6c5212d"
      },
      "source": [
        "Realizo carga de datos para las tareas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "438e31ca",
      "metadata": {
        "id": "438e31ca",
        "outputId": "1b66a803-dcd6-4f71-daad-6c9edfdeb9cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "it can be a very complicated thing the ocean \n",
            "\n",
            "It can be a very complicated thing, the ocean. \n",
            "\n",
            "And it can be a very complicated thing, what human health is. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Carga\n",
        "with open('PunctuationTask.test.en') as f:\n",
        "    PunctuationTaskTestEn = f.readlines()\n",
        "with open('PunctuationTask.check.en') as f:\n",
        "    PunctuationTaskCheckEn = f.readlines()\n",
        "# Sin utf-8 me falla el corpus\n",
        "with open('PunctuationTask.train.en', encoding='utf-8') as f:\n",
        "    PunctuationTaskTrainEn = f.readlines()\n",
        "\n",
        "# Verificacion\n",
        "print(PunctuationTaskTestEn[0])\n",
        "print(PunctuationTaskCheckEn[0])\n",
        "print(PunctuationTaskTrainEn[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef14b8fc",
      "metadata": {
        "id": "ef14b8fc"
      },
      "source": [
        "Resolución de Apartado 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4671b404",
      "metadata": {
        "id": "4671b404"
      },
      "outputs": [],
      "source": [
        "def addPunctuationBasic(line):\n",
        "    # Caso especial\n",
        "    if(line == ''):\n",
        "        return ''\n",
        "    # Convertimos el primer caracter de la oración a mayuscula\n",
        "    first_letter = line[0].upper()\n",
        "    return first_letter + line[1:] + '.'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdcdd2b2",
      "metadata": {
        "id": "cdcdd2b2"
      },
      "source": [
        "Prueba con ejemplo de enunciado y corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc3f7d41",
      "metadata": {
        "id": "dc3f7d41",
        "outputId": "f3c12379-d7fd-469d-e88a-edd58fac538c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It can be a very complicated thing the ocean.\n",
            "We made the ocean unhappy we made people very unhappy and we made them unhealthy \n",
            ".\n"
          ]
        }
      ],
      "source": [
        "frase = 'it can be a very complicated thing the ocean'\n",
        "print(addPunctuationBasic(frase))\n",
        "print(addPunctuationBasic(PunctuationTaskTestEn[3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33872e54",
      "metadata": {
        "id": "33872e54"
      },
      "source": [
        "## Apartado 2\n",
        "Implementar la función verifyPunctuation con la siguiente signatura\n",
        "`[(pos,err)] verifyPunctuation(string check, string test)`\n",
        "\n",
        "Para realizar esta operación se llevará a cabo una tokenización de ambos strings. En este caso se\n",
        "considerarán tokens todas las secuencias de letras, números y cualquier otro signo que no sea uno de\n",
        "los seis indicados como signos de puntuación en este ejercicio (`.,;:?!`)\n",
        "Es decir, esta función devolverá una lista de pares, donde cada par contendrá la posición (indicada\n",
        "como índice en el string check) y el tipo de error. Los errores posibles son:\n",
        "* ‘I’ → Insertion\n",
        "* ‘D’ → Deletion\n",
        "* ‘S’ → Substitution\n",
        "\n",
        "Por ejemplo, consideremos que el string de referencia correcto (check) es\n",
        "“Hello. What’s your name?”\n",
        "La tokenización generará los siguientes 6 tokens de referencia\n",
        "* Token 0: Hello\n",
        "* Token 1: .\n",
        "* Token 2: What’s\n",
        "* Token 3: your\n",
        "* Token 4: name\n",
        "* Token 5: ?\n",
        "\n",
        "Consideremos que nuestro algoritmo de puntuación (un caso hipotético para analizar el algoritmo de\n",
        "verificación) genera la siguiente salida\n",
        ">“Hello what’s your, name?”\n",
        "\n",
        "Es decir los tokens generados en este caso son:\n",
        "* Token 0: Hello\n",
        "* Token 1: what’s\n",
        "* Token 2: your\n",
        "* Token 3: ,\n",
        "* Token 4: name\n",
        "* Token 5: ?\n",
        "\n",
        "Debemos devolver la lista de cambios necesarios para convertir la cadena de tokens generados\n",
        "(hipótesis) en la cadena de tokens correctos. Para ello, podemos inspirarnos en el algoritmo de la\n",
        "distancia de Levenshtein. Es importante tener en cuenta que dadas dos cadenas A y B:\n",
        "> Dist(A,B) == Dist(B,A)\n",
        "\n",
        "Por lo que podemos abordar el problema tanto desde el punto de los cambios que hay que hacer para\n",
        "llegar desde la hipótesis hasta el modelo correcto, o bien desde el modelo correco (referencia o check\n",
        "en la terminología de este ejercicio) hasta la hipótesis generada por nuestro algoritmo de puntuación.\n",
        "Podemos ver que respecto a nuestro string de referencia (check), el string de test ha ignorado (podemos\n",
        "decir que borrado respecto al de referencia un ., por tanto tendríamos el error\n",
        ">(‘D’,1)\n",
        "\n",
        "En segundo lugar, el token 2 del string de referencia (check) se ha quedado mal en el string de test ya\n",
        "que en lugar de “What’s” aparece “what’s”. Se trata por tanto de un error de substitución de una palabra\n",
        "por otra (en este caso por un error de introducción de mayúsculas):\n",
        ">(‘S’,2)\n",
        "\n",
        "Y en tercer lugar, entre los tokens ‘your’ y ‘name’ del string correcto (check) se ha introducido un\n",
        "nuevo token en el string de test, una coma en concreto, por tanto hay un error que calificaríamos como\n",
        ">(‘I’,4)\n",
        "\n",
        "Como se puede observar, todos los errores se posicionan (usan los índices) respecto al string correcto\n",
        "de referencia (check).\n",
        "Así pues el resultado de\n",
        "\n",
        "`verifyPunctuation(“Hello. What’s your name?”, “Hello what’s your, name?”)`\n",
        "\n",
        "sería\n",
        "\n",
        "> [ (‘D’,1), (‘S’,2), (‘I’, 4) ]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70d24c67",
      "metadata": {
        "id": "70d24c67"
      },
      "source": [
        "Con la siguiente función tokenizo por palabras considerando tokens cuando estas se encuentran separadas por espacios o tokens reservados. De esta forma generar una lista de tokens para tratar las frases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71127441",
      "metadata": {
        "id": "71127441"
      },
      "outputs": [],
      "source": [
        "# Funcion para tokenizar\n",
        "def tokenizador(texto, tokens):\n",
        "    \n",
        "    # Verificacion strings con datos\n",
        "    if len(texto) == 0: return 0\n",
        "    texto_tokenizado = []\n",
        "    \n",
        "    # Generacion de tokens\n",
        "    start = 0\n",
        "    for i in range(len(texto)):\n",
        "        # Espacios\n",
        "        if texto[i] == ' ':\n",
        "            texto_tokenizado.append(texto[start:i])\n",
        "            start=i+1  \n",
        "        # Analisis de prueba con tokens\n",
        "        for j in range (len(tokens)):\n",
        "            # tokens\n",
        "            if texto[i] == tokens[j]:\n",
        "                texto_tokenizado.append(texto[start:i])\n",
        "                start=i\n",
        "    return texto_tokenizado"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1de7f2b",
      "metadata": {
        "id": "f1de7f2b"
      },
      "source": [
        "Inspirandome en el algoritmo de Levenshtein reutilice la funcion referenciada aqui: https://python-course.eu/applications-python/levenshtein-distance.php para generar una matriz que me permita encontrar el recorrido optimo con las reglas minimales de insercion (insertion), borrado (deletion) y reemplazo (substitution). Al utilizar el algoritmo indicado obtuve una representación distinta a la recomendad en el enunciado como minimal en la salida de verifyPunctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "015d7972",
      "metadata": {
        "id": "015d7972"
      },
      "outputs": [],
      "source": [
        "def iterative_levenshtein(s, t):\n",
        "    \"\"\" \n",
        "        iterative_levenshtein(s, t) -> ldist\n",
        "        ldist is the Levenshtein distance between the strings \n",
        "        s and t.\n",
        "        For all i and j, dist[i,j] will contain the Levenshtein \n",
        "        distance between the first i characters of s and the \n",
        "        first j characters of t\n",
        "    \"\"\"\n",
        "\n",
        "    rows = len(s)+1\n",
        "    cols = len(t)+1\n",
        "    dist = [[0 for x in range(cols)] for x in range(rows)]\n",
        "\n",
        "    # source prefixes can be transformed into empty strings \n",
        "    # by deletions:\n",
        "    for i in range(1, rows):\n",
        "        dist[i][0] = i\n",
        "\n",
        "    # target prefixes can be created from an empty source string\n",
        "    # by inserting the characters\n",
        "    for i in range(1, cols):\n",
        "        dist[0][i] = i\n",
        "        \n",
        "    for col in range(1, cols):\n",
        "        for row in range(1, rows):\n",
        "            if s[row-1] == t[col-1]:\n",
        "                cost = 0\n",
        "            else:\n",
        "                cost = 1\n",
        "            dist[row][col] = min(dist[row-1][col] + 1,      # deletion\n",
        "                                 dist[row][col-1] + 1,      # insertion\n",
        "                                 dist[row-1][col-1] + cost) # substitution\n",
        "    return dist"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f236d91",
      "metadata": {
        "id": "1f236d91"
      },
      "source": [
        "Función para encontrar el recorrido mínimo con matriz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5a345d1",
      "metadata": {
        "id": "b5a345d1"
      },
      "outputs": [],
      "source": [
        "def minimal_operations(matriz_levenshtein, check_len, test_len):\n",
        "  \n",
        "    col = test_len\n",
        "    row = check_len\n",
        "    problemas = []\n",
        "    while col > 1 and row > 1:\n",
        "            \n",
        "        minimo = min(matriz_levenshtein[row-1][col],      # deletion\n",
        "                        matriz_levenshtein[row][col-1],   # insertion\n",
        "                        matriz_levenshtein[row-1][col-1]) # substitution\n",
        "        \n",
        "        # Insertion\n",
        "        if col == 1:\n",
        "            while row > 1:\n",
        "                problemas.append(\"I,\"+str(row))\n",
        "                row = row - 1\n",
        "                \n",
        "        # Insertion\n",
        "        elif row == 1:\n",
        "            while col > 1:\n",
        "                problemas.append(\"D,\"+str(row))\n",
        "                col = col - 1\n",
        "        \n",
        "        # Diagonalizo        \n",
        "        elif matriz_levenshtein[row-1][col-1] == minimo:\n",
        "            if matriz_levenshtein[row-1][col-1] == matriz_levenshtein[row][col] - 1:\n",
        "                # Substitution\n",
        "                problemas.append(\"S,\"+str(row))\n",
        "            col = col - 1\n",
        "            row = row - 1\n",
        "        elif matriz_levenshtein[row-1][col] == minimo:\n",
        "            # Deletion\n",
        "            problemas.append(\"D,\"+str(row))\n",
        "            row = row - 1\n",
        "        else:\n",
        "            # Insertion\n",
        "            problemas.append(\"I,\"+str(row))\n",
        "            col = col - 1\n",
        " \n",
        "    return np.flip(problemas)   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5127822f",
      "metadata": {
        "id": "5127822f"
      },
      "source": [
        "Agregue un parámetro de reporte para poder visualizar la matriz y la posibilidad de no tokenizar asi procesa la información por carácter en vez de por token (palabra)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "159784eb",
      "metadata": {
        "id": "159784eb"
      },
      "outputs": [],
      "source": [
        "def verifyPunctuation(check, test, tokenizar=True, extended_report=False):\n",
        "    \"\"\" \n",
        "        Analizamos distancias según casos posibles combinando situaciones\n",
        "        Agregue reporte para poder visualizar la matriz en las pruebas\n",
        "        Agregue tokenizador para simplificar el procesamiento ya que el enunciado no es claro\n",
        "    \"\"\" \n",
        "    # Caso especial\n",
        "    if(check == '' or test == ''):\n",
        "        return [('D', 0), ('S', 0), ('I', 0)]\n",
        "    # Tokens reservados\n",
        "    reserve_tokens = ['.',',',';',':','?','!']\n",
        "\n",
        "    if tokenizar:\n",
        "        # Tokenizamos input\n",
        "        data_check = tokenizador(check, reserve_tokens)\n",
        "        data_test = tokenizador(test, reserve_tokens)\n",
        "    else:\n",
        "        data_check = check\n",
        "        data_test = test\n",
        "\n",
        "    matriz_levenshtein = iterative_levenshtein(data_check, data_test)\n",
        "\n",
        "    # Generar reporte\n",
        "    if extended_report:\n",
        "        # Impresion de verificacion, opcional\n",
        "        print('DATOS CORRECTOS')\n",
        "        print(data_check)\n",
        "        print('DATOS A SER PROBADOS')\n",
        "        print(data_test)\n",
        "        \n",
        "        # Impresion Matriz Levenshtein opcional\n",
        "        rows = len(data_check)+1\n",
        "        for r in range(rows):\n",
        "            print(matriz_levenshtein[r])\n",
        "            \n",
        "    # Exportar camino\n",
        "    # return minimal_operations(matriz_levenshtein, len(data_check), len(data_test))\n",
        "    return minimal_operations(matriz_levenshtein, len(data_check), len(data_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee148b3e",
      "metadata": {
        "id": "ee148b3e",
        "outputId": "5a9a2513-9950-4b66-b647-3fc3bec2bdb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['S,2' 'S,3' 'S,4']\n",
            "We made the ocean unhappy; we made people very unhappy, and we made them unhealthy. \n",
            "\n",
            "we made the ocean unhappy we made people very unhappy and we made them unhealthy \n",
            "\n"
          ]
        }
      ],
      "source": [
        "str1 = 'Hello. What’s your name?'\n",
        "str2 = 'Hello what’s your, name?'\n",
        "\n",
        "print(verifyPunctuation(str1,str2, tokenizar = False, extended_report = False ))\n",
        "# ['D,6' 'S,8' 'I,18']\n",
        "print(verifyPunctuation(str1,str2, tokenizar = True, extended_report = False))\n",
        "# ['S,2' 'S,3' 'S,4']\n",
        "print(PunctuationTaskCheckEn[3])\n",
        "print(PunctuationTaskTestEn[3])\n",
        "print(verifyPunctuation(PunctuationTaskCheckEn[3],PunctuationTaskTestEn[3], tokenizar = True))\n",
        "print(verifyPunctuation(PunctuationTaskCheckEn[3],PunctuationTaskTestEn[3], tokenizar = False))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e3cf9a5",
      "metadata": {
        "id": "7e3cf9a5"
      },
      "source": [
        "## Apartado 3\n",
        "\n",
        "Implementar una herramienta que permita recorrer todo el corpus de test y verificación. Es decir, iría\n",
        "recorriendo una a una las líneas de cada fichero (que están alineadas), aplicaría sobre la frase de test el\n",
        "algoritmo básico de puntuación (apartado 1: `addPunctuationBasic()` ) y a continuación\n",
        "comprobaría si el resultado es o no correcto usando la función `verifyPunctuation()` del\n",
        "apartado 2.\n",
        "\n",
        "Obtener a continuación los valores relativos a `precisión`, exhaustividad (`recall`) y `F1` para el algoritmo\n",
        "`addPunctuationBasic()` implementado en el apartado 1.\n",
        "\n",
        "Consideraremos estos valores como el baseline, el modelo más básico de puntuación que podemos\n",
        "realizar para estudiar posibles mejoras."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d987c515",
      "metadata": {
        "id": "d987c515"
      },
      "source": [
        "Funciones de `Accuracy`, `Precision`, `Recall` y `F1` basado en https://www.analyticslane.com/2019/10/09/numpy-basico-inicializacion-de-arrays-en-numpy/\n",
        "\n",
        "Reporte general que voy a usar en los demas enunciados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3ecd97d",
      "metadata": {
        "id": "e3ecd97d"
      },
      "outputs": [],
      "source": [
        "def reporteConMetricas(check, test, punctuationBasic = False):\n",
        "    \n",
        "    # Como los valores verdaderos son de check, asumo todos verdaderos ya que no tengo un algoritmo de prediccion\n",
        "    y_true = np.ones(len(test))\n",
        "    \n",
        "    # Inicio mi vector de prediccion al cual voy a agregarle el resultado de mi verifyOuntuaction\n",
        "    y_pred = np.zeros(len(test))\n",
        "    \n",
        "    # Variables\n",
        "    tp = 0\n",
        "    fp = 0\n",
        "    fn = 0\n",
        "    \n",
        "    # Proceso\n",
        "    for i in tqdm(range(len(test)),ncols = 100 , desc =\"Verifico Metricas ...\", disable = True):\n",
        "        if punctuationBasic:\n",
        "            test_proceced = addPunctuationBasic(test[i])\n",
        "        else:\n",
        "            test_proceced = test[i]\n",
        "        \n",
        "        analysis = len(verifyPunctuation(check[i], test_proceced)) > 0\n",
        "        # Verificacion\n",
        "        if not analysis:\n",
        "            y_pred[i] = 1\n",
        "    \n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    precision = tp / (tp + fp)\n",
        "    recall = tp / (tp + fn)     \n",
        "    f1 = ((precision * recall)/(precision + recall)) * 2\n",
        "    \n",
        "    return (precision * 100, recall * 100, f1 * 100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f86e557",
      "metadata": {
        "id": "9f86e557",
        "outputId": "82c73f5d-73a8-4d98-be16-a1098d285024"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrica de implementacion Basica \n",
            " Precision: 100.0 \n",
            " Recall: 0.2989848421638159 \n",
            " F1: 0.5961871750433275 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "precision, recall, f1 = reporteConMetricas(PunctuationTaskCheckEn, PunctuationTaskTestEn)\n",
        "print(\"Metrica de implementacion Basica \\n Precision: %s \\n Recall: %s \\n F1: %s \\n\" % (precision, recall, f1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c3b3b39",
      "metadata": {
        "id": "9c3b3b39"
      },
      "source": [
        "El resultado de las métricas indican que la herramienta desarrollada nos puede servir como una primer aproximación a la solución de problemas de puntuación aunque existen múltiples variantes con n-gramas, operación con ventanas, uso de distintos modelos en simultáneo o redes neuronales profundas que pueden brindar una significativa mejora en la predicción de la puntuación."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43750914",
      "metadata": {
        "id": "43750914"
      },
      "source": [
        "## Apartado 4\n",
        "\n",
        "Utilizando el corpus de entrenamiento contenido en PunctuationTask.train.en construir un modelo de\n",
        "lenguaje inspirado en la idea de 4-gramas. No es exactamente un 4-grama pero está basado en dicho\n",
        "modelo.\n",
        "El objetivo de este pseudo 4-grama será predecir si en la posición P de un string debemos introducir un\n",
        "signo de puntuación (siempre estamos restringiendo el alcance a los seis signos de puntuación\n",
        "considerados en este ejercicio), o si debemos cambiar la palabra en dicha posición P por mayúscula.\n",
        "En última instancia, el 4-grama contendrá tuplas de la siguiente forma:\n",
        "\n",
        "\n",
        "`(token1, token2, token3, operación)`\n",
        "\n",
        "donde token1, token2 y token3 serán tokens cualesquiera incluidos en el corpus de entrenamiento. Por\n",
        "tanto estos tokens podrán ser palabras o signos de puntuación, y ‘operación’ será una de las siguientes\n",
        "operaciones:\n",
        "\n",
        "`signo de puntuación (que podrá ser uno de los seis considerados: .,;;?!`\n",
        "\n",
        "`mayúscula (que indica que la siguiente palabra se debe poner en mayúscula)`\n",
        "\n",
        "`minúscula (que indica que la siguiente palabra deberá estar en minúscula)`\n",
        "\n",
        "La operación se decide observando el fenómeno más común (frecuencia relativa) de las distintas\n",
        "operaciones para cada tríada de tokens (token1 token2 token3).\n",
        "Por ejemplo, podríamos detectar que para la tríada de tokens\n",
        "`(‘by’, ‘the’, ‘way’)`\n",
        "la operación más frecuente es insertar el signo de puntuación coma (,)\n",
        "Una vez creado este modelo de lenguaje se debe implementar una segunda versión de la función que\n",
        "añade signos de puntuación denominada\n",
        "`string addPunctuation4gram(string)`\n",
        "\n",
        "que recibirá como en el apartado 1 un string de entrada, y devolverá el nuevo string con los cambios\n",
        "introducidos aplicando el modelo de lenguaje previamente entrenado con el 4-grama previamente\n",
        "indicado.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "829d611c",
      "metadata": {
        "id": "829d611c"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "token_regular_expression = r'[^.,:;?\\s]+|[.,:;?]'\n",
        "character_regular_expression = '([.,;:?!])'\n",
        "\n",
        "\n",
        "def processTrainData(train_data):\n",
        "    model_data = ' '.join(train_data).rstrip()\n",
        "    tokens = re.findall(token_regular_expression, model_data)\n",
        "    n_grams = []\n",
        "    for i in range(0, len(tokens)-4):\n",
        "        j = i+4\n",
        "        n_grams.append(tokens[i:j])\n",
        "    train_grams = np.array(n_grams)\n",
        "\n",
        "    salida = {}\n",
        "    \n",
        "    for n_gram in train_grams:\n",
        "        word_4ngram = n_gram[3]\n",
        "        clave_palabra = ''.join(n_gram[0:3])\n",
        "        next = ''\n",
        "        if re.search(character_regular_expression, word_4ngram):\n",
        "            next = 'C ' + word_4ngram\n",
        "        elif word_4ngram[0].isupper():\n",
        "            next = 'M'\n",
        "        elif word_4ngram[0].isupper() != True:\n",
        "            next = 'm'\n",
        "\n",
        "        if clave_palabra in salida:\n",
        "            salida[clave_palabra] = np.append(salida[clave_palabra], next)\n",
        "        else:\n",
        "            salida[clave_palabra] = np.array([next])\n",
        "\n",
        "    \n",
        "    for clave_palabra in salida:\n",
        "        unique, counts = np.unique(salida[clave_palabra], return_counts=True)\n",
        "        common = np.where(counts == max(counts))\n",
        "        salida[clave_palabra] = unique[common]\n",
        "\n",
        "    return salida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2def03c",
      "metadata": {
        "id": "f2def03c"
      },
      "outputs": [],
      "source": [
        "def addPunctuation4gram(test_data, train_data):\n",
        "    \n",
        "    train_data = processTrainData(train_data)\n",
        "\n",
        "    output = []\n",
        "    \n",
        "    for w in tqdm(range(len(test_data)),ncols = 100 , desc =\" Entrenando ...\", disable = True):\n",
        "        tokens = re.findall(token_regular_expression, test_data[w])\n",
        "        i = 0\n",
        "        \n",
        "        # Proceso principal\n",
        "        while i < len(tokens)-4:\n",
        "            sentence = tokens[i: i+4]\n",
        "            items = sentence[0:3]\n",
        "            key =  ''.join(items)\n",
        "            if key in train_data:\n",
        "                value = train_data[key][0]\n",
        "\n",
        "                if 'C' in value:\n",
        "                    target_token = tokens[i+3]\n",
        "                    character =  value.split()[1]\n",
        "                    if target_token != character:\n",
        "                        tokens.insert(i+3,character)\n",
        "                elif 'M' in value:\n",
        "                    target_token = tokens[i+3]\n",
        "                    if target_token[0].isupper() != True:\n",
        "                        tokens[i+3] = target_token.capitalize()\n",
        "                elif 'm' in value:\n",
        "                    target_token = tokens[i+3]\n",
        "                    if target_token[0].isupper():\n",
        "                        tokens[i+3] = target_token.lower()\n",
        "\n",
        "            i+=1\n",
        "            \n",
        "        transformation = ' '.join(tokens)\n",
        "        # Agrego el trabajo de Apartado 1\n",
        "        transformation = addPunctuationBasic(transformation)\n",
        "        output.append(transformation)\n",
        "    \n",
        "    return output\n",
        "\n",
        "# Ejecucion para reporte en Apartado 5\n",
        "punctuation4gram_data = addPunctuation4gram(PunctuationTaskTestEn, PunctuationTaskTrainEn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45d5a05f",
      "metadata": {
        "id": "45d5a05f"
      },
      "source": [
        "## Apartado 5\n",
        "\n",
        "Aplicar el modelo de verificación implementado en el apartado 2, pero contrastando el corpus de\n",
        "referencia con el resultado generado por el algoritmo de puntuación basado en 4-gramas del apartado 4.\n",
        "A continuación obtener los valores de precisión, exhaustividad (recall) y F1 sobre estos nuevos\n",
        "resultados y compararlos con los obtenidos en el apartado 3.\n",
        "Este nuevo algoritmo de puntuación basado en 4-gramas, ¿mejora los resultados? Analiza si mejora o\n",
        "empeora, ¿por qué puede ocurrir?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a7cf1b2",
      "metadata": {
        "id": "2a7cf1b2",
        "outputId": "e27af8c8-b4c1-45e5-d9bf-5219dc7375b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrica de implementacion Basica \n",
            " Precision: 100.0 \n",
            " Recall: 0.2989848421638159 \n",
            " F1: 0.5961871750433275 \n",
            "\n",
            "Metrica de 4-grams \n",
            " Precision: 100.0 \n",
            " Recall: 0.32679738562091504 \n",
            " F1: 0.6514657980456027 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Original\n",
        "precision, recall, f1 = reporteConMetricas(PunctuationTaskCheckEn, PunctuationTaskTestEn)\n",
        "print(\"Metrica de implementacion Basica \\n Precision: %s \\n Recall: %s \\n F1: %s \\n\" % (precision, recall, f1))\n",
        "\n",
        "#4-grams\n",
        "n_precision, n_recall, n_f1 = reporteConMetricas(PunctuationTaskCheckEn, punctuation4gram_data, punctuationBasic = False)\n",
        "print(\"Metrica de 4-grams \\n Precision: %s \\n Recall: %s \\n F1: %s \\n\" % (n_precision, n_recall, n_f1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "469107fa",
      "metadata": {
        "id": "469107fa"
      },
      "source": [
        "Los resultados que se pueden observar muestran que a pesar del entrenamiento con el corpus con 4-gramas no logra una mejora significativa dada la información con la que se evalúa aunque se sospecha que la implementación de tokenización puede ser la responsable del bajo rendimiento de ambos modelos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78853924",
      "metadata": {
        "id": "78853924"
      },
      "source": [
        "## Apartado 6\n",
        "\n",
        "Utilizando también ejemplos de TED talks, en un artículo de 2016, Ottokar Tilk y Tanel Alum ha\n",
        "aplicado un modelo de redes recurrentes bidireccionales para esta misma tarea (restauración de signos\n",
        "de puntuación en textos no segmentados).\n",
        "El artículo donde lo describen se encuentra publicado en este enlace:\n",
        "\n",
        "* https://www.isca-speech.org/archive/Interspeech_2016/pdfs/1517.PDF\n",
        "* Bidirectional Recurrent Neural Network with Attention Mechanism forPunctuation Restoration (InterSpeech 2016).\n",
        "\n",
        "El código correspondiente a su implementación se encuentra también disponible en github:\n",
        "\n",
        "* https://github.com/ottokart/punctuator2\n",
        "\n",
        "Los resultados de la evaluación para tres signos de puntuación concretos han sido estos (disponibles en\n",
        "la dirección github anterior):\n",
        "\n",
        "|PUNCTUATION | PRECISION | RECALL  | F-SCORE|\n",
        "|:----|:----|:----|:----|\n",
        "|,COMMA | 64.4 | 45.2 | 53.1|\n",
        "|?QUESTIONMARK | 67.5 | 58.7 |  62.8|\n",
        "|.PERIOD | 72.3 | 71.5 | 71.9|\n",
        "|Overall | 68.9 | 58.1 | 63.1|\n",
        "\n",
        "El objetivo de este apartado es estudiar la implementación que han hecho estos autores con una red\n",
        "neuronal y adecuarla al problema que se ha planteado en este ejercicio.\n",
        "\n",
        "En concreto, este apartado consistirá en la adecuación del modelo de Tilk y Alum al escenario de este\n",
        "ejercicio. Es decir, aplicar el entrenamiento de la red propuesta por estos autores al corpus de\n",
        "entrenamiento (PuntuationTask.train.en) y a continuación evaluar el resultado obtenido usando el\n",
        "modelo de verificación implementado previamente.\n",
        "\n",
        "Los resultados que obtienes para tu evaluación son similares a los publicados por estos autores.\n",
        "\n",
        "Nota: Observar el modelo implementado por estos autores en el script error_calculator.py, como\n",
        "contraste a vuestro algoritmo de verificación (apartado 2) y evaluación (apartados 3 y 5).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "282f83e8",
      "metadata": {
        "id": "282f83e8"
      },
      "source": [
        "#### Análisis del modelo:\n",
        "\n",
        "\n",
        "El modelo opera con texto no segmentado a través de un tipo de red neuronal recurrente. Entonces evita el trabajo de tokenizado en componentes más pequeños.\n",
        "\n",
        "El modelo busca resolver específicamente problemas con comas, puntos, signos de exclamación, dos puntos, signos de interrogación los puntos y rayas.\n",
        "\n",
        "El modelo BRNN permite utilizar contextos de tamaño no fijo antes y después de la posición actual de procesado.\n",
        "\n",
        "Las capas recurrentes usan un tipo de unidad recurrente cerrada (GRU) para capturar dependencias de largo alcance en distintas unidades de tiempo. De esta forma las unidades tienen las mismas ventajas que las unidades LSTM pero siendo más sencillas en definitiva.\n",
        "\n",
        "Este modelo se implementa con la librería theano y los pesos se van actualizando con un learning rate de 0.02.\n",
        "\n",
        "\n",
        "#### Comparativa con el modelo realizado\n",
        "\n",
        "El modelo propuesto en los apartados anteriores al ser comparado con esté arroja una métrica inferior dado que la capacidad de aprendizaje con el corpus de entrenamiento le brinda más flexibilidad a la hora de obtener el comportamiento deseado con los sets de prueba."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ddd6a5c",
      "metadata": {
        "id": "8ddd6a5c"
      },
      "source": [
        "## Apartado 7\n",
        "\n",
        "A partir del trabajo realizado y teniendo en cuenta otros enfoques disponibles en el ámbito de las\n",
        "tecnologías del lenguaje, investiga qué otros enfoques o estrategias alternativas para esta misma tarea.\n",
        "El objetivo de este apartado es que busques bibliografía relevante reciente sobre esta tarea, selecciones\n",
        "uno o dos artículos y describas brevemente el enfoque y resultados obtenidos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13a44b98",
      "metadata": {
        "id": "13a44b98"
      },
      "source": [
        "* A 43 Language Multilingual Punctuation Prediction Neural Network Model\n",
        "\n",
        "El modelo se basa en BPE multi-idioma la cual es una técnica de compresión de datos que permite representar las palabras en unidades pequeñas reduciendo la dispersión de las palabras compartiendo unidades (subpalabras entre distintas palabras). Los investigadores demuestran que un modelo multilingüe que considere la compatibilidad entre varios idiomas, a diferencia de los modelos monolingües tradicionales puede mejorar la precisión. En el artículo demuestran que un solo modelo multilingüe basado en BPE puede lograr un rendimiento similar o superior a los modelos monolingües por separado basados en palabras. EL modelo logra un puntaje F1 promedio del 80,2% analizando noticias mientras que en el reconocimiento de voz fuera del dominio logra un puntaje de 73,3% en F1.\n",
        "\n",
        "\n",
        "EL modelo presenta los siguientes resultados al combinar idiomas.\n",
        "\n",
        "Español intersectado con la unión de Francés e italiano en un 93.2%.\n",
        "Francés  intersectado con la unión de Italiano y Español en un 95,4%.\n",
        "Italiano intersectado con la unión de Francés y ESpañol en un 95,8%.\n",
        "\n",
        "ref: https://indico2.conference4me.psnc.pl/event/35/contributions/2972/attachments/610/641/Mon-3-1-9.pdf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9c61de1",
      "metadata": {
        "id": "e9c61de1"
      },
      "source": [
        "* Token-Level Supervised Contrastive Learning for Punctuation Restoration\n",
        "\n",
        "En este trabajo se unifican varias estrategias de codificación existentes para predecir la puntuación utilizando múltiples predicciones en cada palabra en diferentes ventanas. Los investigadores demuestran que se pueden lograr mejoras significativas al optimizar estrategias luego de entrenar un modelo aumentando el tiempo de respuesta sin necesidad de re-entrenamiento.\n",
        "\n",
        "El modelo propuesto logra una mejora sustancial cuando hay poco o ningún contexto en el right-side al entrenar. La estrategia que utilizan es usar un token [PUNCT] que informa al modelo de la posición de la puntuación que se va a predecir. Los textos de entrada se tokenizan y la predicción se da evaluando múltiples posibles lugares donde el token de puntuación debiera ser insertado. Además se optimiza el tamaño de ventana y la longitud de zancada al momento de la clasificación. Por último cuando se debe elegir entre un modelo u otro existe una compensación entre la latencia y la precisión entre modelos. De esta forma se utiliza un modelo de clasificación cuando no hay un contexto futuro mientras que un modelo de etiquetado es usado cuando hay contexto del lado derecho a predecir.\n",
        "\n",
        "Los valores generales que ambos modelos logran en F1 para enfoques de clasificación y etiquetado  para la predicción de puntuación en tiempo real con anticipación (lookahead) de hasta 4 es de 76,3% en TAgging y 73,9 en clasificación, mientras que sin anticipación l = 0 el modelo de Tagging logra 42,1% y el de clasificación 47,3%\n",
        "\n",
        "ref: https://arxiv.org/pdf/2112.08098v2.pdf"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "pln-mulcia-exam-lorenz-vieta.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
